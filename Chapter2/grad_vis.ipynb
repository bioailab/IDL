{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Google Colaboratory (if needed)\n",
    "Set the variable `colab` to `True` if you are using this notebook from Google Colaboratory, else set it to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = False  # Set to true if working on Google Colaboratory\n",
    "\n",
    "if colab:\n",
    "    # Mount your Google Drive for storage\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Save to, and access files from, your Google Drive if using Colaboratory \n",
    "    ROOT_DIR = '/content/drive/MyDrive/IDL'\n",
    "    \n",
    "    # Fetch the git repository\n",
    "    !git clone https://github.com/AyushSomani001/IDL {ROOT_DIR}\n",
    "\n",
    "else:\n",
    "     ROOT_DIR = '..'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Cvs94Cf77x-"
   },
   "outputs": [],
   "source": [
    "reqs_file = f'{ROOT_DIR}/requirements.txt'\n",
    "!pip install -r {reqs_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "## Progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder where the datasets are/should be downloaded (e.g. MNIST)\n",
    "DATASET_PATH = \"D:/Nirwan/Ayush sir/data\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"D:/Nirwan/Ayush sir/saved_models/tutorial3\"\n",
    "\n",
    "# Function for setting the seed\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): # GPU operation have separate seed\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "set_seed(42)\n",
    "\n",
    "# Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
    "# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationFunction(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.name = self.__class__.__name__\n",
    "        self.config = {\"name\": self.name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "\n",
    "class Sigmoid(ActivationFunction):\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "##############################\n",
    "\n",
    "class Tanh(ActivationFunction):\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_exp, neg_x_exp = torch.exp(x), torch.exp(-x)\n",
    "        return (x_exp - neg_x_exp) / (x_exp + neg_x_exp)\n",
    "\n",
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "\n",
    "class ReLU(ActivationFunction):\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * (x > 0).float()\n",
    "\n",
    "##############################\n",
    "\n",
    "class LeakyReLU(ActivationFunction):\n",
    "\n",
    "    def __init__(self, alpha=0.1):\n",
    "        super().__init__()\n",
    "        self.config[\"alpha\"] = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.where(x > 0, x, self.config[\"alpha\"] * x)\n",
    "\n",
    "##############################\n",
    "\n",
    "class ELU(ActivationFunction):\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.where(x > 0, x, torch.exp(x)-1)\n",
    "\n",
    "##############################\n",
    "\n",
    "class Swish(ActivationFunction):\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_fn_by_name = {\n",
    "    \"sigmoid\": Sigmoid,\n",
    "    \"tanh\": Tanh,\n",
    "    \"relu\": ReLU,\n",
    "    \"leakyrelu\": LeakyReLU,\n",
    "    \"elu\": ELU,\n",
    "    \"swish\": Swish\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grads(act_fn, x):\n",
    "    \"\"\"\n",
    "    Computes the gradients of an activation function at specified positions.\n",
    "\n",
    "    Inputs:\n",
    "        act_fn - An object of the class \"ActivationFunction\" with an implemented forward pass.\n",
    "        x - 1D input tensor.\n",
    "    Output:\n",
    "        A tensor with the same size of x containing the gradients of act_fn at x.\n",
    "    \"\"\"\n",
    "    x = x.clone().requires_grad_() # Mark the input as tensor for which we want to store gradients\n",
    "    out = act_fn(x)\n",
    "    out.sum().backward() # Summing results in an equal gradient flow to each element in x\n",
    "    return x.grad # Accessing the gradients of x by \"x.grad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_act_fn(act_fn, ax, x):\n",
    "    # Run activation function\n",
    "    y = act_fn(x)\n",
    "    y_grads = get_grads(act_fn, x)\n",
    "    # Push x, y and gradients back to cpu for plotting\n",
    "    x, y, y_grads = x.cpu().numpy(), y.cpu().numpy(), y_grads.cpu().numpy()\n",
    "    ## Plotting\n",
    "    ax.plot(x, y, linewidth=2, label=\"ActFn\")\n",
    "    ax.plot(x, y_grads, linewidth=2, label=\"Gradient\")\n",
    "    ax.set_title(act_fn.name)\n",
    "    ax.legend()\n",
    "    ax.set_ylim(-1.5, x.max())\n",
    "\n",
    "# Add activation functions if wanted\n",
    "act_fns = [act_fn() for act_fn in act_fn_by_name.values()]\n",
    "x = torch.linspace(-5, 5, 1000) # Range on which we want to visualize the activation functions\n",
    "## Plotting\n",
    "rows = math.ceil(len(act_fns)/2.0)\n",
    "fig, ax = plt.subplots(rows, 2, figsize=(8, rows*4))\n",
    "for i, act_fn in enumerate(act_fns):\n",
    "    vis_act_fn(act_fn, ax[divmod(i,2)], x)\n",
    "fig.subplots_adjust(hspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, act_fn, input_size=784, num_classes=10, hidden_sizes=[128, 256, 512, 1024, 512, 256, 128]):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            act_fn - Object of the activation function that should be used as non-linearity in the network.\n",
    "            input_size - Size of the input images in pixels\n",
    "            num_classes - Number of classes we want to predict\n",
    "            hidden_sizes - A list of integers specifying the hidden layer sizes in the NN\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Create the network based on the specified hidden sizes\n",
    "        layers = []\n",
    "        layer_sizes = [input_size] + hidden_sizes\n",
    "        for layer_index in range(1, len(layer_sizes)):\n",
    "            layers += [nn.Linear(layer_sizes[layer_index-1], layer_sizes[layer_index]),\n",
    "                       act_fn]\n",
    "        layers += [nn.Linear(layer_sizes[-1], num_classes)]\n",
    "        self.layers = nn.Sequential(*layers) # nn.Sequential summarizes a list of modules into a single module, applying them in sequence\n",
    "\n",
    "        # We store all hyperparameters in a dictionary for saving and loading of the model\n",
    "        self.config = {\"act_fn\": act_fn.config, \"input_size\": input_size, \"num_classes\": num_classes, \"hidden_sizes\": hidden_sizes}\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # Reshape images to a flat vector\n",
    "        out = self.layers(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_config_file(model_path, model_name):\n",
    "    # Name of the file for storing hyperparameter details\n",
    "    return os.path.join(model_path, model_name + \".config\")\n",
    "\n",
    "def _get_model_file(model_path, model_name):\n",
    "    # Name of the file for storing network parameters\n",
    "    return os.path.join(model_path, model_name + \".tar\")\n",
    "\n",
    "def load_model(model_path, model_name, net=None):\n",
    "    \"\"\"\n",
    "    Loads a saved model from disk.\n",
    "\n",
    "    Inputs:\n",
    "        model_path - Path of the checkpoint directory\n",
    "        model_name - Name of the model (str)\n",
    "        net - (Optional) If given, the state dict is loaded into this model. Otherwise, a new model is created.\n",
    "    \"\"\"\n",
    "    config_file, model_file = _get_config_file(model_path, model_name), _get_model_file(model_path, model_name)\n",
    "    assert os.path.isfile(config_file), f\"Could not find the config file \\\"{config_file}\\\". Are you sure this is the correct path and you have your model config stored here?\"\n",
    "    assert os.path.isfile(model_file), f\"Could not find the model file \\\"{model_file}\\\". Are you sure this is the correct path and you have your model stored here?\"\n",
    "    with open(config_file, \"r\") as f:\n",
    "        config_dict = json.load(f)\n",
    "    if net is None:\n",
    "        act_fn_name = config_dict[\"act_fn\"].pop(\"name\").lower()\n",
    "        act_fn = act_fn_by_name[act_fn_name](**config_dict.pop(\"act_fn\"))\n",
    "        net = BaseNetwork(act_fn=act_fn, **config_dict)\n",
    "    net.load_state_dict(torch.load(model_file, map_location=device))\n",
    "    return net\n",
    "\n",
    "def save_model(model, model_path, model_name):\n",
    "    \"\"\"\n",
    "    Given a model, we save the state_dict and hyperparameters.\n",
    "\n",
    "    Inputs:\n",
    "        model - Network object to save parameters from\n",
    "        model_path - Path of the checkpoint directory\n",
    "        model_name - Name of the model (str)\n",
    "    \"\"\"\n",
    "    config_dict = model.config\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    config_file, model_file = _get_config_file(model_path, model_name), _get_model_file(model_path, model_name)\n",
    "    with open(config_file, \"w\") as f:\n",
    "        json.dump(config_dict, f)\n",
    "    torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "# Transformations applied on each image => first make them a tensor, then normalize them in the range -1 to 1\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Loading the training dataset. We need to split it into a training and validation part\n",
    "train_dataset = MNIST(root=DATASET_PATH, train=True, transform=transform, download=True)\n",
    "train_set, val_set = torch.utils.data.random_split(train_dataset, [50000, 10000])\n",
    "\n",
    "# Loading the test set\n",
    "test_set = MNIST(root=DATASET_PATH, train=False, transform=transform, download=True)\n",
    "\n",
    "# We define a set of data loaders that we can use for various purposes later.\n",
    "# Note that for actually training a model, we will use different data loaders\n",
    "# with a lower batch size.\n",
    "train_loader = data.DataLoader(train_set, batch_size=1024, shuffle=True, drop_last=False)\n",
    "val_loader = data.DataLoader(val_set, batch_size=1024, shuffle=False, drop_last=False)\n",
    "test_loader = data.DataLoader(test_set, batch_size=1024, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exmp_imgs = [train_set[i][0] for i in range(16)]\n",
    "# Organize the images into a grid for nicer visualization\n",
    "img_grid = torchvision.utils.make_grid(torch.stack(exmp_imgs, dim=0), nrow=4, normalize=True, pad_value=0.5)\n",
    "img_grid = img_grid.permute(1, 2, 0)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title(\"MNIST examples\")\n",
    "plt.imshow(img_grid)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_gradients(net, color=\"C0\"):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        net - Object of class BaseNetwork\n",
    "        color - Color in which we want to visualize the histogram (for easier separation of activation functions)\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    small_loader = data.DataLoader(train_set, batch_size=256, shuffle=False)\n",
    "    imgs, labels = next(iter(small_loader))\n",
    "    imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "    # Pass one batch through the network, and calculate the gradients for the weights\n",
    "    net.zero_grad()\n",
    "    preds = net(imgs)\n",
    "    loss = F.cross_entropy(preds, labels)\n",
    "    loss.backward()\n",
    "    # We limit our visualization to the weight parameters and exclude the bias to reduce the number of plots\n",
    "    grads = {name: params.grad.data.view(-1).cpu().clone().numpy() for name, params in net.named_parameters() if \"weight\" in name}\n",
    "    net.zero_grad()\n",
    "\n",
    "    ## Plotting\n",
    "    columns = len(grads)\n",
    "    fig, ax = plt.subplots(1, columns, figsize=(columns*3.5, 2.5))\n",
    "    fig_index = 0\n",
    "    for key in grads:\n",
    "        key_ax = ax[fig_index%columns]\n",
    "        sns.histplot(data=grads[key], bins=30, ax=key_ax, color=color, kde=True)\n",
    "        key_ax.set_title(str(key))\n",
    "        key_ax.set_xlabel(\"Grad magnitude\")\n",
    "        fig_index += 1\n",
    "    fig.suptitle(f\"Gradient magnitude distribution for activation function {net.module.config['act_fn']['name']}\", fontsize=14, y=1.05)\n",
    "    fig.subplots_adjust(wspace=0.45)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn prints warnings if histogram has small values. We can ignore them for now\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "## Create a plot for every activation function\n",
    "for i, act_fn_name in enumerate(act_fn_by_name):\n",
    "    set_seed(42) # Setting the seed ensures that we have the same weight initialization for each activation function\n",
    "    act_fn = act_fn_by_name[act_fn_name]()\n",
    "    net_actfn = BaseNetwork(act_fn=act_fn)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")    \n",
    "        net_actfn = nn.DataParallel(net_actfn)\n",
    "    net_actfn.to(device)\n",
    "    visualize_gradients(net_actfn, color=f\"C{i+2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, model_name, max_epochs=50, patience=7, batch_size=256, overwrite=False):\n",
    "    \"\"\"\n",
    "    Train a model on the training set of FashionMNIST\n",
    "\n",
    "    Inputs:\n",
    "        net - Object of BaseNetwork\n",
    "        model_name - (str) Name of the model, used for creating the checkpoint names\n",
    "        max_epochs - Number of epochs we want to (maximally) train for\n",
    "        patience - If the performance on the validation set has not improved for #patience epochs, we stop training early\n",
    "        batch_size - Size of batches used in training\n",
    "        overwrite - Determines how to handle the case when there already exists a checkpoint. If True, it will be overwritten. Otherwise, we skip training.\n",
    "    \"\"\"\n",
    "    file_exists = os.path.isfile(_get_model_file(CHECKPOINT_PATH, model_name))\n",
    "    if file_exists and not overwrite:\n",
    "        print(\"Model file already exists. Skipping training...\")\n",
    "    else:\n",
    "        if file_exists:\n",
    "            print(\"Model file exists, but will be overwritten...\")\n",
    "\n",
    "        # Defining optimizer, loss and data loader\n",
    "        optimizer = optim.SGD(net.parameters(), lr=1e-2, momentum=0.9) # Default parameters, feel free to change\n",
    "        loss_module = nn.CrossEntropyLoss()\n",
    "        train_loader_local = data.DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
    "\n",
    "        val_scores = []\n",
    "        best_val_epoch = -1\n",
    "        for epoch in range(max_epochs):\n",
    "            ############\n",
    "            # Training #\n",
    "            ############\n",
    "            net.train()\n",
    "            true_preds, count = 0., 0\n",
    "            for imgs, labels in tqdm(train_loader_local, desc=f\"Epoch {epoch+1}\", leave=False):\n",
    "                imgs, labels = imgs.to(device), labels.to(device) # To GPU\n",
    "                optimizer.zero_grad() # Zero-grad can be placed anywhere before \"loss.backward()\"\n",
    "                preds = net(imgs)\n",
    "                loss = loss_module(preds, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                # Record statistics during training\n",
    "                true_preds += (preds.argmax(dim=-1) == labels).sum()\n",
    "                count += labels.shape[0]\n",
    "            train_acc = true_preds / count\n",
    "\n",
    "            ##############\n",
    "            # Validation #\n",
    "            ##############\n",
    "            val_acc = test_model(net, val_loader)\n",
    "            val_scores.append(val_acc)\n",
    "            print(f\"[Epoch {epoch+1:2d}] Training accuracy: {train_acc*100.0:05.2f}%, Validation accuracy: {val_acc*100.0:05.2f}%\")\n",
    "\n",
    "            if len(val_scores) == 1 or val_acc > val_scores[best_val_epoch]:\n",
    "                print(\"\\t   (New best performance, saving model...)\")\n",
    "                save_model(net, CHECKPOINT_PATH, model_name)\n",
    "                best_val_epoch = epoch\n",
    "            elif best_val_epoch <= epoch - patience:\n",
    "                print(f\"Early stopping due to no improvement over the last {patience} epochs\")\n",
    "                break\n",
    "\n",
    "        # Plot a curve of the validation accuracy\n",
    "        plt.plot([i for i in range(1,len(val_scores)+1)], val_scores)\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Validation accuracy\")\n",
    "        plt.title(f\"Validation performance of {model_name}\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    load_model(CHECKPOINT_PATH, model_name, net=net)\n",
    "    test_acc = test_model(net, test_loader)\n",
    "    print((f\" Test accuracy: {test_acc*100.0:4.2f}% \").center(50, \"=\")+\"\\n\")\n",
    "    return test_acc\n",
    "\n",
    "\n",
    "def test_model(net, data_loader):\n",
    "    \"\"\"\n",
    "    Test a model on a specified dataset.\n",
    "\n",
    "    Inputs:\n",
    "        net - Trained model of type BaseNetwork\n",
    "        data_loader - DataLoader object of the dataset to test on (validation or test)\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    true_preds, count = 0., 0\n",
    "    for imgs, labels in data_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            preds = net(imgs).argmax(dim=-1)\n",
    "            true_preds += (preds == labels).sum().item()\n",
    "            count += labels.shape[0]\n",
    "    test_acc = true_preds / count\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for act_fn_name in act_fn_by_name:\n",
    "    print(f\"Training BaseNetwork with {act_fn_name} activation...\")\n",
    "    set_seed(42)\n",
    "    act_fn = act_fn_by_name[act_fn_name]()\n",
    "    net_actfn = BaseNetwork(act_fn=act_fn)\n",
    "    net_actfn.to(device)\n",
    "    train_model(net_actfn, f\"MNIST_{act_fn_name}\", overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_activations(net, color=\"C0\"):\n",
    "    activations = {}\n",
    "\n",
    "    net.eval()\n",
    "    small_loader = data.DataLoader(train_set, batch_size=1024)\n",
    "    imgs, labels = next(iter(small_loader))\n",
    "    with torch.no_grad():\n",
    "        layer_index = 0\n",
    "        imgs = imgs.to(device)\n",
    "        imgs = imgs.view(imgs.size(0), -1)\n",
    "        # We need to manually loop through the layers to save all activations\n",
    "        for layer_index, layer in enumerate(net.layers[:-1]):\n",
    "            imgs = layer(imgs)\n",
    "            activations[layer_index] = imgs.view(-1).cpu().numpy()\n",
    "\n",
    "    ## Plotting\n",
    "    columns = 4\n",
    "    rows = math.ceil(len(activations)/columns)\n",
    "    fig, ax = plt.subplots(rows, columns, figsize=(columns*2.7, rows*2.5))\n",
    "    fig_index = 0\n",
    "    for key in activations:\n",
    "        key_ax = ax[fig_index//columns][fig_index%columns]\n",
    "        sns.histplot(data=activations[key], bins=50, ax=key_ax, color=color, kde=True, stat=\"density\")\n",
    "        key_ax.set_title(f\"Layer {key} - {net.layers[key].__class__.__name__}\")\n",
    "        fig_index += 1\n",
    "    fig.suptitle(f\"Activation distribution for activation function {net.config['act_fn']['name']}\", fontsize=14)\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, act_fn_name in enumerate(act_fn_by_name):\n",
    "    net_actfn = load_model(model_path=CHECKPOINT_PATH, model_name=f\"MNIST_{act_fn_name}\").to(device)\n",
    "    visualize_activations(net_actfn, color=f\"C{i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_number_dead_neurons(net):\n",
    "\n",
    "    # For each neuron, we create a boolean variable initially set to 1. If it has an activation unequals 0 at any time,\n",
    "    # we set this variable to 0. After running through the whole training set, only dead neurons will have a 1.\n",
    "    neurons_dead = [\n",
    "        torch.ones(layer.weight.shape[0], device=device, dtype=torch.bool) for layer in net.layers[:-1] if isinstance(layer, nn.Linear)\n",
    "    ] # Same shapes as hidden size in BaseNetwork\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(train_loader, leave=False): # Run through whole training set\n",
    "            layer_index = 0\n",
    "            imgs = imgs.to(device)\n",
    "            imgs = imgs.view(imgs.size(0), -1)\n",
    "            for layer in net.layers[:-1]:\n",
    "                imgs = layer(imgs)\n",
    "                if isinstance(layer, ActivationFunction):\n",
    "                    # Are all activations == 0 in the batch, and we did not record the opposite in the last batches?\n",
    "                    neurons_dead[layer_index] = torch.logical_and(neurons_dead[layer_index], (imgs == 0).all(dim=0))\n",
    "                    layer_index += 1\n",
    "    number_neurons_dead = [t.sum().item() for t in neurons_dead]\n",
    "    print(\"Number of dead neurons:\", number_neurons_dead)\n",
    "    print(\"In percentage:\", \", \".join([f\"{(100.0 * num_dead / tens.shape[0]):4.2f}%\" for tens, num_dead in zip(neurons_dead, number_neurons_dead)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "net_relu = BaseNetwork(act_fn=ReLU()).to(device)\n",
    "measure_number_dead_neurons(net_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_relu = load_model(model_path=CHECKPOINT_PATH, model_name=\"MNIST_relu\").to(device)\n",
    "measure_number_dead_neurons(net_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "net_relu = BaseNetwork(act_fn=ReLU(), hidden_sizes=[256, 256, 256, 256, 256, 128, 128, 128, 128, 128]).to(device)\n",
    "measure_number_dead_neurons(net_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad1c0dbef3f641073a34f09f455f49b782999c8c2b68a6221dd4f2e8b792020f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
